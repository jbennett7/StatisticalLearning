{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6894e8-7fb7-4bcd-a0d3-d6511507de41",
   "metadata": {},
   "source": [
    "# Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e099b-e655-4b36-9cff-5f5ae58a78cc",
   "metadata": {},
   "source": [
    "__1.__  For each of parts (a) through (d), indicate whether we would generqally expect the performance of a flexible statistical learning method to be better or wrose than an inflexible method. Justify your answer.  \n",
    "\n",
    "  __a.__ The sample size $n$ is extremely large, and the number of predictors $p$ is small.  \n",
    "         _The flexible model takes advantage of the large sample size._  \n",
    "     \n",
    "  __b.__ The number of predictors $p$ is extremely large, and the number of observations $n$ is small.  \n",
    "         _The flexible model would cause overfitting because of the small sample size._\n",
    "  \n",
    "  __c.__ The relationship between the predictors and response is highly non-linear.  \n",
    "         _The flexible model is the best to find the nonlinear effect._\n",
    "  \n",
    "  __d.__ The variance of the error terms, i.e. $\\sigma^2 = \\text{Var}(\\epsilon)$, is extremely high.  \n",
    "         _The flexible model would incorporate the irreducible noise into the model_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f41450-64f0-4caa-8af0-89f150a8ec88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dcafc8-1974-4207-ba5d-33bced15f411",
   "metadata": {},
   "source": [
    "__2.__ Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally provide $n$ and $p$.  \n",
    "\n",
    "(a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.  \n",
    "\n",
    "__SOLUTION__ This is a regression and inference problem, $n = 500$ the number of firms, and the predictors $p$ are: (1) profit, (2) number of employees, (3) industry, and (4) CEO salary.  \n",
    "\n",
    "(b) We are considering launching a new product and wish to know whether it will be a _success_ or a _failure_. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.  \n",
    "\n",
    "__SOLUTION__ This is a classificaiton and prediction problem, $n = 20$ and the predictors $p$ are: (1) price, (2) marketing budget, (3) competition price, (4) ten other variables.\n",
    "\n",
    "(c) We are interested in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.  \n",
    "\n",
    "__SOLUTION__ This is a regression and prediction problem, $n = 52$ weeks and the predictors $p$ are: (1) % change in USD/Euro, (2) % change in US market, (3) % change in the British market, (4) % change in the German market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f77fb0-ab03-4ad5-aa4f-f1160142c8cf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b9dfb-a275-415e-86ee-349535f011f2",
   "metadata": {},
   "source": [
    "__3.__ We now revisit the bias-variance decomposition.  \n",
    "\n",
    "(a) Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The _x_-axis should represent the amount of flexibility in the method, and the _y_-axis should represent the values for each curve. There should be five curves. Make sure to label each one.\n",
    "\n",
    "__SOLUTION__  \n",
    "![Bias-Variance](Bias-Variance.png \"Bias-Variance\")\n",
    "\n",
    "(b) Explain why each of the five curves has the shape displayed in part (a).  \n",
    "\n",
    "As a general rule, as we use more flexible methods, the variance will increase and the bias will decrease. This is because the flexibility of the model will more fit the training set. The training MSE will steadly decrease as the flexibility of the model increases (fitting the training data). However, as the flexibility increases (fitting the training data) the test MSE will begin to decrease to a minimum and then follow a U turn up as the model fits the training data more and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37062c9-c726-442a-bf95-cab2fa481a6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500f61a-6e14-4beb-a7d0-7e879fa41fa6",
   "metadata": {},
   "source": [
    "__4.__ You will now think of some real-life applications for statistical learning.  \n",
    "\n",
    "(a) Describe three real-life applications in which _classification_ might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.  \n",
    "\n",
    "(b) Describe three real-life applications in which _regression_ might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.  \n",
    "\n",
    "(c) Describe three real-life applications in which _cluster analysis_ might be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed6907-bd1e-47d9-acde-ca5120472559",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb2ee2-c6c3-4cc8-8b76-1d8fdd2cd034",
   "metadata": {},
   "source": [
    "__5.__ What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?  \n",
    "\n",
    "__SOLUTION__  \n",
    "The best way to describe the advantages and disadvantages of very flexible methods to regression or classification is to explain the accuracy versus interpretability tradeoff. The more flexible a method is, the more accurate the model will be in representing the data. However, there is a danger in overfitting with highly flexible methods. The major disadvantage of very flexible methods is that interpretability decreases because the relationship between each predictor and the response is now modeled using a curve. With highly flexible, non-linear methods like _bagging_, _support vector machines_, and _neural networks_ are very hard to interpret.  \n",
    "\n",
    "More flexible approaches are useful when accuracy is more important then interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb4abc-c46d-4fc3-b022-1f57998849f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f2a11-cfd0-4110-814a-931dcacb2a64",
   "metadata": {},
   "source": [
    "__6.__ Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?\n",
    "\n",
    "__SOLUTION__  \n",
    "A Parametric approach to statistical learning involves two steps:  \n",
    "(1) We make an assumption about the functional form, or shape of $f$. A simple assumption is that $f$ is linear in $X$\n",
    "\\begin{align}\\tag{2.4}\n",
    "f(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p\n",
    "\\end{align}  \n",
    "(2) We _fit_ or _train_ the model using training data to estimate the $\\beta$ parameters.  \n",
    "\n",
    "A non-parametric method does not make an assumption about $f$. Instead we seek an estimate of $f$ that gets as close to the dat apoints as possible.\n",
    "\n",
    "A major advantage of a parametric approach to non-parametric approaches is that, for non-parametric approaches, a large number of observations (far more than is typically needed for a parametric approach) is required in order to obtain an accurate estimate for $f$.\n",
    "\n",
    "A major disadvantage of a parametric approach is that you will not be able to truely fit the unknown form of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513299d-ef46-4971-a8e7-6669bc060995",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2d460-a267-4b16-af7b-ee54f158d4e1",
   "metadata": {},
   "source": [
    "__7.__ The table below provides a training data set containing six observations, three predictors, and one qualitative response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ecec01-9277-4895-8205-d70b19838b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>Y</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0</td><td>3</td><td>0</td><td>Red  </td></tr>\n",
       "\t<tr><td> 2</td><td>0</td><td>0</td><td>Red  </td></tr>\n",
       "\t<tr><td> 0</td><td>1</td><td>3</td><td>Red  </td></tr>\n",
       "\t<tr><td> 0</td><td>1</td><td>2</td><td>Green</td></tr>\n",
       "\t<tr><td>-1</td><td>0</td><td>1</td><td>Green</td></tr>\n",
       "\t<tr><td> 1</td><td>1</td><td>1</td><td>Red  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{llll}\n",
       " X1 & X2 & X3 & Y\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t  0 & 3 & 0 & Red  \\\\\n",
       "\t  2 & 0 & 0 & Red  \\\\\n",
       "\t  0 & 1 & 3 & Red  \\\\\n",
       "\t  0 & 1 & 2 & Green\\\\\n",
       "\t -1 & 0 & 1 & Green\\\\\n",
       "\t  1 & 1 & 1 & Red  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| X1 &lt;dbl&gt; | X2 &lt;dbl&gt; | X3 &lt;dbl&gt; | Y &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "|  0 | 3 | 0 | Red   |\n",
       "|  2 | 0 | 0 | Red   |\n",
       "|  0 | 1 | 3 | Red   |\n",
       "|  0 | 1 | 2 | Green |\n",
       "| -1 | 0 | 1 | Green |\n",
       "|  1 | 1 | 1 | Red   |\n",
       "\n"
      ],
      "text/plain": [
       "  X1 X2 X3 Y    \n",
       "1  0 3  0  Red  \n",
       "2  2 0  0  Red  \n",
       "3  0 1  3  Red  \n",
       "4  0 1  2  Green\n",
       "5 -1 0  1  Green\n",
       "6  1 1  1  Red  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Obs <- c(1, 2, 3, 4, 5, 6)\n",
    "X1 <- c(0, 2, 0, 0, -1, 1)\n",
    "X2 <- c(3, 0, 1, 1, 0, 1)\n",
    "X3 <- c(0, 0, 3, 2, 1, 1)\n",
    "Y <- c(\"Red\", \"Red\", \"Red\", \"Green\", \"Green\", \"Red\")\n",
    "(df <- data.frame(X1, X2, X3, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0b77e-84c3-40ec-8329-9842d593132e",
   "metadata": {},
   "source": [
    "Suppose we wish to use this data set to make a prediction for $Y$ when $X_1=X_2=X_3=0$ using $K$-nearest neighbors.  \n",
    "\n",
    "(a) Compute the Euclidean distance between each observation and the test point, $X_1=X_2=X_3=0$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f4588a-8edc-4e33-91c6-4e253553f7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "2 \n",
      "3.162278 \n",
      "2.236068 \n",
      "1.414214 \n",
      "1.732051 \n"
     ]
    }
   ],
   "source": [
    "euclidean <- function(a, b) sqrt(sum((a-b)^2))\n",
    "tp <- c(0,0,0)\n",
    "for (r in 1:nrow(df)){\n",
    "    cat(euclidean(tp, as.numeric(df[r,1:3])), \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb25eae-10e5-4c11-aee8-a9c30b6bcd82",
   "metadata": {},
   "source": [
    "(b) What is our prediction with $K=1$? Why?  \n",
    "Based on the results above, the prediction will be `Green`, (observation 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b2a96-b6a1-43b2-a226-953c666bb74e",
   "metadata": {},
   "source": [
    "(c) What is our prediction with $K=3$? Why?  \n",
    "With $K=3$ the nearest neighbors are observations: 5, 6, and 2. 2 `Red` and 1 `Green`. The prediction will be `Red`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd206ae-81f7-402e-bc4a-2302a25ddda7",
   "metadata": {},
   "source": [
    "(d) If the Bayes decision boundary in this problem is highly non-linear, then would we expect the _best_ value for $K$ to be large or small? Why?  \n",
    "The best value of $K$ would be small because a high $K$ value would not be flexible enough for a highly non-linear boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84135618-52e3-429e-98a5-b3a44fe86593",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
