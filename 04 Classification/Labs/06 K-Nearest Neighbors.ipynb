{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0ebff8-7779-4ff6-9136-4f575e217a96",
   "metadata": {},
   "source": [
    "# 4.7.6 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbd23c-7218-4681-ab4c-36aa58f418ef",
   "metadata": {},
   "source": [
    "We will now perform KNN using the `knn()` function, which is part of the `class` library. This function works rather differently from the other modelfitting functions that we have encountered thus far. Rather than a two-step approach in which we first fit the model and then we use the model to make predictions, `knn()` forms predictions using a single command. The function requires four inputs.  \n",
    "1. A matrix containing the predictors associated with the training data, labeled `train.X` below.\n",
    "2. A matrix containing the predictors associated with the data for which we wish to make predictions, labeled `test.X` below.\n",
    "3. A vector containing the class labels for the training observations, labeled `train.Direction` below.\n",
    "4. A value for K, the number of nearest neighbors to be used by the classifier.\n",
    "We use the `cbind()` function, short for _column bind_, to bind the `Lag1` and `Lag2` variables together into two matrices, one for the training set and the other for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0d164d-04ac-4403-a4dd-8b388ecedf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR2)\n",
    "library(class)\n",
    "attach(Smarket)\n",
    "train <- (Year < 2005)\n",
    "Smarket.2005 <- Smarket[!train,]\n",
    "Direction.2005 <- Direction[!train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7e3f9c-ab86-4122-826c-4b79ef8d57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.X <- cbind(Lag1, Lag2)[train,]\n",
    "test.X <- cbind(Lag1, Lag2)[!train,]\n",
    "train.Direction <- Direction[train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ba65d-0c2b-4607-8e1b-d795b597b03d",
   "metadata": {},
   "source": [
    "Now the `knn()` function can be used to predict the market's movement for the dates in 2005. We set a random seed before we apply `knn()` because if several observations are tied as nearest neighbors, then `R` will randomly break the tie. Therefore, a seed must be set in order to ensure reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cff20f-2dd5-4bb4-9b29-68c87293c5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Direction.2005\n",
       "knn.pred Down Up\n",
       "    Down   43 58\n",
       "    Up     68 83"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "knn.pred <- knn(train.X, test.X, train.Direction, k = 1)\n",
    "table(knn.pred, Direction.2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973e88e3-36b9-4b01-8ce0-515d01dfb94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.5"
      ],
      "text/latex": [
       "0.5"
      ],
      "text/markdown": [
       "0.5"
      ],
      "text/plain": [
       "[1] 0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(83 + 43) / 252"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fb844-c0e1-49e3-895b-1fca65cd9353",
   "metadata": {},
   "source": [
    "The results using $K=1$ are not very good, since only $50%$ of the observations are correctly predicted. Of course, it may be that $K=1$ results in an overly flexible fit to the data. Below, we repeat the analysis using $K=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2629b0c3-58ad-4371-8f3a-5f51b2972a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Direction.2005\n",
       "knn.pred Down Up\n",
       "    Down   48 54\n",
       "    Up     63 87"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.pred <- knn(train.X, test.X, train.Direction, k = 3)\n",
    "table(knn.pred, Direction.2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff266b32-fc0e-42e9-9910-485faf45a76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.535714285714286"
      ],
      "text/latex": [
       "0.535714285714286"
      ],
      "text/markdown": [
       "0.535714285714286"
      ],
      "text/plain": [
       "[1] 0.5357143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(knn.pred == Direction.2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f5fec-d06a-4bec-a9cf-af5ef39bca5b",
   "metadata": {},
   "source": [
    "The results have improved slightly. But increasing K further turns out to provide no further improvements. It appears that for this data, QDA provides the best results of the methods that we have examined so far.  \n",
    "\n",
    "KNN does not perform well on the `Smarket` data but it does often provide impressive results. As an example we will apply the KNN approach to the `Caravan` data set, which is part of teh `ISLR2` library. This data set includes $85$ predictors that measure demographic characteristics for $5,822$ individuals. The response variable is `Purchase`, which indicates whether or not a given individual purchases a caravan insurance policy. In this data set, only $6%$ of people purchased caravan insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07541259-13f5-424a-9693-63291941299a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>5822</li><li>86</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5822\n",
       "\\item 86\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5822\n",
       "2. 86\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5822   86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(Caravan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77911d90-2ac9-4a20-91f2-a21f6b55ac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>No</dt><dd>5474</dd><dt>Yes</dt><dd>348</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[No] 5474\n",
       "\\item[Yes] 348\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "No\n",
       ":   5474Yes\n",
       ":   348\n",
       "\n"
      ],
      "text/plain": [
       "  No  Yes \n",
       "5474  348 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0597732737890759"
      ],
      "text/latex": [
       "0.0597732737890759"
      ],
      "text/markdown": [
       "0.0597732737890759"
      ],
      "text/plain": [
       "[1] 0.05977327"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attach(Caravan)\n",
    "summary(Purchase)\n",
    "348 / 5822"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96718bb8-609f-48fc-96d8-74c4365565f6",
   "metadata": {},
   "source": [
    "Because the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Variables that are on a large scale will have a much larger effect on the _distance_ between the observations, and hence on the KNN classifier, than variables that are on a small scale. For instance, imagine a data set that contains two variables, `salary` and `age` (measured in dollars and years, repsectively). As far as KNN is concerned, a difference of $\\$1,000$ in salary is enormous compared to a difference of $50$ years in age. Consequently, `salary` will drive the KNN classification results, and `age` will have almost no effect. THis is contrary to our intuition that a salary difference of $\\$1,000$ is quite small compared ot an age difference of $50$ years. Furthermore, the importance of scale to the KNN classifier leads to another issue: if we measured `salary` in Japanese yen, or if we measured `age` in minutes, then we'd get quite different classification results from what we get if these two variables are measured in dollars and years.  \n",
    "\n",
    "A good way to handle this problem is to _standardize_ the data so that all variables are given a mean of zero and a standard deviation of one. THen all variables will be on a comparable scale. The `scale()` functio does just this. In standardizing the data, we exclude column 86, because that is the qualitative `Purchase` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0b032d-2abf-4d44-bc0e-3b3e274eb55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "165.037847395189"
      ],
      "text/latex": [
       "165.037847395189"
      ],
      "text/markdown": [
       "165.037847395189"
      ],
      "text/plain": [
       "[1] 165.0378"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "standardized.X <- scale(Caravan[,-86])\n",
    "var(Caravan[,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc9eb09-67ad-4a80-84e5-11706d430b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.164707781931954"
      ],
      "text/latex": [
       "0.164707781931954"
      ],
      "text/markdown": [
       "0.164707781931954"
      ],
      "text/plain": [
       "[1] 0.1647078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var(Caravan[,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f591443d-4dfb-449f-9a44-60b42cb0a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var(standardized.X[,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ddb44e-53db-468c-858a-db975c5e0c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var(standardized.X[,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd8948-0154-4fe3-bf4c-3b8a1ce3b898",
   "metadata": {},
   "source": [
    "Now every column of `standardized.X` has a standard deviation of one and a mean of zero.  \n",
    "\n",
    "We now split the observations into a test set, containing the first $1,000$ observations, and a training set, containing the remaining observations. We fit a KNN model on the training data using $K=1$, and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b801f1-df8a-4e44-b4c5-9554fb9fc8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.118"
      ],
      "text/latex": [
       "0.118"
      ],
      "text/markdown": [
       "0.118"
      ],
      "text/plain": [
       "[1] 0.118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test <- 1:1000\n",
    "train.X <- standardized.X[-test,]\n",
    "test.X <- standardized.X[test,]\n",
    "train.Y <- Purchase[-test]\n",
    "test.Y <- Purchase[test]\n",
    "set.seed(1)\n",
    "knn.pred <- knn(train.X, test.X, train.Y, k = 1)\n",
    "mean(test.Y != knn.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb163362-1de8-45f3-b49c-deef887a2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.059"
      ],
      "text/latex": [
       "0.059"
      ],
      "text/markdown": [
       "0.059"
      ],
      "text/plain": [
       "[1] 0.059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(test.Y != \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e9ed8-c6df-442d-959b-747e0e9e7696",
   "metadata": {},
   "source": [
    "The vector `test` is numeric, with values from $1$ through $1,000$. Typing `standardized.X[test,]` yields the submatrix of the data containing the observations whose indices range from $1$ to $1,000$, whereas typing `standardized.X[-test,]` yields the submatrix containing the observations whose indices do _not_ range from $1$ to $1,000$. THe KNN error rate on the $1,000$ test observations is just under $12%$. At first glance, this may appear to be fairly good. However, since only $6%$ of customers purchased insurance, we could get the error rate down to $6%$ by always predicting `No` regardless of the values of the predictors!  \n",
    "\n",
    "Suppose that there is some non-trivial cost to trying to sell insurance to a given individual. For instance, perhaps a salesperson must visit each potential customer. If the company tires to sell insurance to a random selection of customers, then the success rate will be only $6%$, which may be far too low given the costs involved. Instead, the company would like to try to sell insurance only to customers who are likely to buy it. So the overall error rate is not of interest. Instead, the fraction of individuals that are correctly predicted to buy insurance is of interest.  \n",
    "\n",
    "It turns out that KNN with $K=1$ does far better than random guessing among the customers that are predicted to buy insurance. Among $77$ such customers, $9$, or $11.7%$, actually do purchase insurance. THis is double the rate that one would obtain from random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ae76a8-d94d-4172-b1b7-31ab2aa3349b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        test.Y\n",
       "knn.pred  No Yes\n",
       "     No  873  50\n",
       "     Yes  68   9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(knn.pred, test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e655c4-9185-4874-9e64-4b1a2e5d9202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.116883116883117"
      ],
      "text/latex": [
       "0.116883116883117"
      ],
      "text/markdown": [
       "0.116883116883117"
      ],
      "text/plain": [
       "[1] 0.1168831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "9 / (68 + 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d25bf1-c9f7-480f-9553-a7458fc3dd07",
   "metadata": {},
   "source": [
    "Using $K=3$, the success rate increases to $19%$, and with $K=5$ the rate is $26.7%$. This is over four times the rate that results from random guessing. It appears that KNN is finding some real patterns in a difficult data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a34e4c8-f766-4d19-aa06-7a9df4ed842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        test.Y\n",
       "knn.pred  No Yes\n",
       "     No  920  54\n",
       "     Yes  21   5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.pred <- knn(train.X, test.X, train.Y, k = 3)\n",
    "table(knn.pred, test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a37c8e6-212f-4d6c-8349-c68ed9281531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.192307692307692"
      ],
      "text/latex": [
       "0.192307692307692"
      ],
      "text/markdown": [
       "0.192307692307692"
      ],
      "text/plain": [
       "[1] 0.1923077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "5 / 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e625aef2-0ba2-46cb-b88c-705ede49bec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        test.Y\n",
       "knn.pred  No Yes\n",
       "     No  930  55\n",
       "     Yes  11   4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.pred <- knn(train.X, test.X, train.Y, k = 5)\n",
    "table(knn.pred, test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bc46d1e-bf3f-40d1-8653-dc12279e3994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.266666666666667"
      ],
      "text/latex": [
       "0.266666666666667"
      ],
      "text/markdown": [
       "0.266666666666667"
      ],
      "text/plain": [
       "[1] 0.2666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "4 / 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1410b-d0e0-4f39-bb0a-614c0126a6d1",
   "metadata": {},
   "source": [
    "However, while this strategy is cost-effective, it is worth noting that only $15$ custmers are predicted to purchase insurance using KNN with $K=5$. In practice, the insurance company may wish to expend resources on convincing more than just 15 potential custmers to buy insurance.  \n",
    "\n",
    "As a comparison, we can also fit a logistic regression model to the data. If we use $0.5$ as the predicted probability cut-off for the classifier, then we have a problem: only seven of the test observations are predicted to purchase insurance. Even worse, we are wrong about all of these! However, we are not required to use a cut-off of $0.5$. If we instead predict a purchase any time the predicted probability of purchase exceeds $0.25$, we get much better results: we predict that $33$ people will purchase insurance, and we are correct for about $33%$ of these people. This is over five times better than random guessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deeebd44-c70f-443f-9141-3364fc4542b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n"
     ]
    }
   ],
   "source": [
    "glm.fits <- glm(Purchase ~ ., data = Caravan, family = binomial, subset = -test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37574a31-00f0-43d4-a5cf-322268902922",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.probs <- predict(glm.fits, Caravan[test,], type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b352fd6-8941-48dc-acf2-3ffc2a2ffff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        test.Y\n",
       "glm.pred  No Yes\n",
       "     No  934  59\n",
       "     Yes   7   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.pred <- rep(\"No\", 1000)\n",
    "glm.pred[glm.probs > .5] <- \"Yes\"\n",
    "table(glm.pred, test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95286b1e-24da-47d7-9544-e0cd1ab9a47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        test.Y\n",
       "glm.pred  No Yes\n",
       "     No  919  48\n",
       "     Yes  22  11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.pred <- rep(\"No\", 1000)\n",
    "glm.pred[glm.probs > .25] <- \"Yes\"\n",
    "table(glm.pred, test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71429c2b-4b00-4ce8-b886-7474f3d5f502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.333333333333333"
      ],
      "text/latex": [
       "0.333333333333333"
      ],
      "text/markdown": [
       "0.333333333333333"
      ],
      "text/plain": [
       "[1] 0.3333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "11 / (22 + 11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
